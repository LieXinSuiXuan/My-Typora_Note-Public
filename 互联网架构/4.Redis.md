# Redis



## 非关系型数据库

库和表之间没有任何关联关系

使用的是kv存储，key value 键值对形式存储

非关系型数据库中没有关联的概念，所有的数据都存放在一张表里面，直接调用数据本身，每个数据没有关联关系，也不会建立关联关

系，只需要直接拿取相关数据的索引

redis是一个典型的非关系数据库，有着检索速度快的优势，所以一般被用来当作mariadb的缓存



## 使用场景

redis作为非关系型数据库但是一般不当作数据库来使用，通常被用作mariadb的缓存，但是当刷新流量大的时候，是不需要配置缓存的



## 配置步骤

### 1.安装、编译redis

```shell
#解压redis的tar包，然后进行编译
[root@node3 ~]# tar -zxvf redis-7.0.0\ \(1\).tar.gz 
[root@node3 ~]# cd redis-7.0.0/src/
[root@node3 src]# make PREFIX=/usr/bin/local/redis MALLOC=libc install 
```



### 2.将redis配置到环境变量

```shell
[root@node3 redis]# cat /etc/profile.d/redis.sh  
export PATH=$PATH:/usr/bin/local/redis/bin 
[root@node3 redis]# . !$ 
[root@node3 redis]# redis-server  --version 
Redis server v=7.0.0 sha=00000000:0 malloc=libc bits=64 build=7aa698c81175c707
[root@node3 redis]# cd /usr/bin/local/redis 
```



### 3.创建redis配置文件，并启动redis

```shell
[root@node3 redis]#mkdir etc data logs 
[root@node3 etc]# cat /usr/bin/local/redis/etc/redis.conf  
daemonize yes 
supervised systemd

#pid存放的位置
pidfile /var/run/redis.pid 
#监听的端口
port 6379 
#日志的存放位置
logfile "/usr/bin/local/redis/logs/redis.log" 
dbfilename dump.rdb
#持久化数据存放位置 
dir /usr/bin/local/redis/data/

#缓存持久化最大存储空间
maxmemory 1G 

#监听地址位置
bind 192.168.1.13 127.0.0.1 

#超时时间和日志级别
timeout 300 
loglevel notice 

#redis默认创建数据库数量
databases 16 

#存储持久化刷新时间
save 900 1 
save 300 10 
save 60 10000 

rdbcompression yes 

maxclients 10000 

#是否开启二进制日志，并设置二进制日志名称
appendonly yes 
appendfilename appendonly.aof 
appendfsync everysec 
[root@node3 etc]# redis-server  /usr/bin/local/redis/etc/redis.conf  
[root@node3 etc]# netstat  -ntpl 
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:3306            0.0.0.0:*               LISTEN      1246/mariadbd       
tcp        0      0 127.0.0.1:6379          0.0.0.0:*               LISTEN      4023/redis-server 1 
tcp        0      0 192.168.1.13:6379       0.0.0.0:*               LISTEN      4023/redis-server 1 
tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      733/rpcbind         
tcp        0      0 192.168.122.1:53        0.0.0.0:*               LISTEN      2137/dnsmasq        
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1118/sshd           
tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN      1120/cupsd          
tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      1415/master         
tcp        0      0 127.0.0.1:6010          0.0.0.0:*               LISTEN      1976/sshd: root@pts 
tcp6       0      0 :::3306                 :::*                    LISTEN      1246/mariadbd       
tcp6       0      0 :::111                  :::*                    LISTEN      733/rpcbind         
tcp6       0      0 :::22                   :::*                    LISTEN      1118/sshd           
tcp6       0      0 ::1:631                 :::*                    LISTEN      1120/cupsd          
tcp6       0      0 ::1:25                  :::*                    LISTEN      1415/master         
tcp6       0      0 ::1:6010                :::*                    LISTEN      1976/sshd: root@pts 
```



### 4.登录redis客户端查看详细信息

```shell
[root@node3 etc]# redis-cli  -h 127.0.0.1 -p 6379 
127.0.0.1:6379> info 
# Server
redis_version:7.0.0
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:7aa698c81175c707
redis_mode:standalone
os:Linux 3.10.0-1160.el7.x86_64 x86_64
arch_bits:64
monotonic_clock:POSIX clock_gettime
multiplexing_api:epoll
atomicvar_api:atomic-builtin
gcc_version:4.8.5
process_id:4023
process_supervised:no
run_id:a26e748170297a14d0365ee463ff8617eccbe6ce
tcp_port:6379
server_time_usec:1653296781222003
uptime_in_seconds:370
uptime_in_days:0
hz:10
configured_hz:10
lru_clock:9129613
executable:/usr/bin/local/redis/etc/redis-server
config_file:/usr/bin/local/redis/etc/redis.conf
io_threads_active:0

# Clients
connected_clients:1
cluster_connections:0
maxclients:10000
client_recent_max_input_buffer:16392
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0

# Memory
used_memory:996824
used_memory_human:973.46K
used_memory_rss:3227648
used_memory_rss_human:3.08M
used_memory_peak:1174104
used_memory_peak_human:1.12M
used_memory_peak_perc:84.90%
used_memory_overhead:952712
used_memory_startup:950688
used_memory_dataset:44112
used_memory_dataset_perc:95.61%
allocator_allocated:977952
allocator_active:3195904
allocator_resident:3195904
total_system_memory:5702983680
total_system_memory_human:5.31G
used_memory_lua:31744
used_memory_vm_eval:31744
used_memory_lua_human:31.00K
used_memory_scripts_eval:0
number_of_cached_scripts:0
number_of_functions:0
number_of_libraries:0
used_memory_vm_functions:32768
used_memory_vm_total:64512
used_memory_vm_total_human:63.00K
used_memory_functions:216
used_memory_scripts:216
used_memory_scripts_human:216B
maxmemory:1000000000
maxmemory_human:953.67M
maxmemory_policy:noeviction
allocator_frag_ratio:3.27
allocator_frag_bytes:2217952
allocator_rss_ratio:1.00
allocator_rss_bytes:0
rss_overhead_ratio:1.01
rss_overhead_bytes:31744
mem_fragmentation_ratio:3.30
mem_fragmentation_bytes:2249696
mem_not_counted_for_evict:24
mem_replication_backlog:0
mem_total_replication_buffers:0
mem_clients_slaves:0
mem_clients_normal:1784
mem_cluster_links:0
mem_aof_buffer:24
mem_allocator:libc
active_defrag_running:0
lazyfree_pending_objects:0
lazyfreed_objects:0

# Persistence
loading:0
async_loading:0
current_cow_peak:0
current_cow_size:0
current_cow_size_age:0
current_fork_perc:0.00
current_save_keys_processed:0
current_save_keys_total:0
rdb_changes_since_last_save:0
rdb_bgsave_in_progress:0
rdb_last_save_time:1653296411
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:-1
rdb_current_bgsave_time_sec:-1
rdb_saves:0
rdb_last_cow_size:0
rdb_last_load_keys_expired:0
rdb_last_load_keys_loaded:0
aof_enabled:1
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_rewrites:0
aof_rewrites_consecutive_failures:0
aof_last_write_status:ok
aof_last_cow_size:0
module_fork_in_progress:0
module_fork_last_cow_size:0
aof_current_size:0
aof_base_size:0
aof_pending_rewrite:0
aof_buffer_length:0
aof_pending_bio_fsync:0
aof_delayed_fsync:0

# Stats
total_connections_received:1
total_commands_processed:1
instantaneous_ops_per_sec:0
total_net_input_bytes:41
total_net_output_bytes:169406
instantaneous_input_kbps:0.00
instantaneous_output_kbps:0.00
rejected_connections:5
sync_full:0
sync_partial_ok:0
sync_partial_err:0
expired_keys:0
expired_stale_perc:0.00
expired_time_cap_reached_count:0
expire_cycle_cpu_milliseconds:4
evicted_keys:0
evicted_clients:0
total_eviction_exceeded_time:0
current_eviction_exceeded_time:0
keyspace_hits:0
keyspace_misses:0
pubsub_channels:0
pubsub_patterns:0
latest_fork_usec:0
total_forks:0
migrate_cached_sockets:0
slave_expires_tracked_keys:0
active_defrag_hits:0
active_defrag_misses:0
active_defrag_key_hits:0
active_defrag_key_misses:0
total_active_defrag_time:0
current_active_defrag_time:0
tracking_total_keys:0
tracking_total_items:0
tracking_total_prefixes:0
unexpected_error_replies:0
total_error_replies:0
dump_payload_sanitizations:0
total_reads_processed:2
total_writes_processed:3
io_threaded_reads_processed:0
io_threaded_writes_processed:0
reply_buffer_shrinks:1
reply_buffer_expands:0

# Replication
role:master
connected_slaves:0
master_failover_state:no-failover
master_replid:b55e9c0241c865da37d9979851f4207ab91dfa53
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0

# CPU
used_cpu_sys:0.310261
used_cpu_user:0.000000
used_cpu_sys_children:0.000000
used_cpu_user_children:0.000000
used_cpu_sys_main_thread:0.310226
used_cpu_user_main_thread:0.000000

# Modules

# Errorstats

# Cluster
cluster_enabled:0

# Keyspace
127.0.0.1:6379> 
```





## 常见数据类型



### key

字符类型，字符串



### value

*   string：字符串类型 不仅包含字符串，还包含数字，包含二进制，图片
*   list：列表类型
*   set：集合类型
*   sorted set：有序集合类型
*   hash ：hash表（python中的字典）



### 基本操作

```shell
keys *                   #显示当前库中所有的key    
exists key               #测试指定key是否存在，返回1表示存在，0不存在
del key1 key2 ....keyN   #删除给定key,返回删除key的数目，0表示给定key都不存在
type key                 #返回给定key的value类型。返回 none 表示不存在key,string字符类型，list 链表类型 set 无序集合类						   型...
keys pattern             #返回匹配指定模式的所有key,下面给个例子
randomkey                #返回从当前数据库中随机选择的一个key,如果当前数据库是空的，返回空串
rename oldkey newkey     #原子的重命名一个key,如果newkey存在，将会被覆盖，返回1表示成功，0失败。可能是oldkey不存在或者和                             newkey相同
renamenx oldkey newkey   #同上，但是如果newkey存在返回失败
dbsize                   #返回当前数据库的key数量
expire key seconds       #为key指定过期时间，单位是秒。返回1成功，0表示key已经设置过过期时间或者不存在
ttl key                  #返回设置过过期时间的key的剩余过期秒数 -1表示key不存在或者没有设置过过期时间
select db-index          #通过索引选择数据库，默认连接的数据库所有是0,默认数据库数是16个。返回1表示成功，0失败   
move key db-index        #将key从当前数据库移动到指定数据库。返回1成功。0 如果key不存在，或者已经在指定数据库中   
flushdb                  #删除当前数据库中所有key,此方法不会失败。慎用   
flushall                 #删除所有数据库中的所有key，此方法不会失败。更加慎用
```



### String基本操作

```shell
set key value                               #设置key对应的值为string类型的value,返回1表示成功，0失败
setnx key value                             #同上，如果key已经存在，返回0 。nx 是not exist的意思
get key                                     #获取key对应的string值,如果key不存在返回nil
getset key value                            #原子的设置key的值，并返回key的旧值。如果key不存在返回nil
mget key1 key2 ... keyN                     #一次获取多个key的值，如果对应key不存在，则对应返回nil
mset key1 value1 ... keyN valueN         	#一次设置多个key的值，成功返回1表示所有的值都设置了，失败返回0表示没有任何值被设置
msetnx key1 value1 ... keyN valueN     	    #同上，但是不会覆盖已经存在的key
incr key                                    #对key的值做加加操作,并返回新的值。注意incr一个不是int的value会返回错误，incr一个不存在的key，则设置key为1
decr key                                    #同上，但是做的是减减操作，decr一个不存在key，则设置key为-1
incrby key integer                          #同incr，加指定值 ，key不存在时候会设置key，并认为原来的value是 0
decrby key integer                          #同decr，减指定值。decrby完全是为了可读性，我们完全可以通过incrby一个负值来实现同样效果，反之一样。
append key value                            #给指定key的字符串值追加value,返回新字符串值的长度。下面给个例子
substr key start end                        #返回截取过的key的字符串值,注意并不修改key的值。下标是从0开始的，接着上面例子
```





### List基本操作

```shell
lpush key string                #在key对应list的头部添加字符串元素，返回1表示成功，0表示key存在且不是list类型
rpush key string                #同上，在尾部添加
llen key                        #返回key对应list的长度，key不存在返回0,如果key对应类型不是list返回错误
lrange key start end            #返回指定区间内的元素，下标从0开始，负值表示从后面计算，-1表示倒数第一个元素 ，key不存在返回空列表
ltrim key start end             #截取list，保留指定区间内元素，成功返回1，key不存在返回错误
lset key index value            #设置list中指定下标的元素值，成功返回1，key或者下标不存在返回错误
lrem key count value            #从key对应list中删除count个和value相同的元素。count为0时候删除全部
lpop key                        #从list的头部删除元素，并返回删除元素。如果key对应list不存在或者是空返回nil，如果key对应值不是list返回错误
rpop                            #同上，但是从尾部删除
blpop key1...keyN timeout     	#从左到右扫描返回对第一个非空list进行lpop操作并返回，比如blpop list1 list2 list3 0 ,如果list不存在list2,list3都是非空则对list2做lpop并返回从list2中删除的元素。如果所有的list都是空或不存在，则会阻塞timeout秒，timeout为0表示一直阻塞。当阻塞时，如果有client对key1...keyN中的任意key进行push操作，则第一在这个key上被阻塞的client会立即返回。如果超时发生，则返回nil。有点像unix的select或者poll
brpop                          	#同blpop，一个是从头部删除一个是从尾部删除
rpoplpush srckey destkey    	#从srckey对应list的尾部移除元素并添加到destkey对应list的头部,最后返回被移除的元素值，整个操作是原子的.如果srckey是空或者不存在返回nil
```



### Set基本操作

```shell
sadd key member                       #添加一个string元素到,key对应的set集合中，成功返回1,如果元素以及在集合中返回0,key对应的set不存在返回错误
srem key member                       #从key对应set中移除给定元素，成功返回1，如果member在集合中不存在或者key不存在返回0，如果key对应的不是set类型的值返回错误
spop key                              #删除并返回key对应set中随机的一个元素,如果set是空或者key不存在返回nil
srandmember key                       #同spop，随机取set中的一个元素，删除元素
smove srckey dstkey member            #从srckey对应set中移除member并添加到dstkey对应set中，整个操作是原子的。成功返回1,如果member在srckey中不存在返回0，如果key不是set类型返回错误
scard key                             #返回set的元素个数，如果set是空或者key不存在返回0
sismember key member                  #判断member是否在set中，存在返回1，0表示不存在或者key不存在
sinter key1 key2...keyN               #返回所有给定key的交集
sinterstore dstkey key1...keyN        #同sinter，但是会同时将交集存到dstkey下
sunion key1 key2...keyN               #返回所有给定key的并集
sunionstore dstkey key1...keyN     	  #同sunion，并同时保存并集到dstkey下
sdiff key1 key2...keyN                #返回所有给定key的差集
sdiffstore dstkey key1...keyN         #同sdiff，并同时保存差集到dstkey下
smembers key                          #返回key对应set的所有元素，结果是无序的
```



### Sorted Set基本操作

```shell
zadd key score member           #添加元素到集合，元素在集合中存在则更新对应score
zrem key member                 #删除指定元素，1表示成功，如果元素不存在返回0
zincrby key incr member         #增加对应member的score值，然后移动元素并保持skip list保持有序。返回更新后的score值
zrank key member                #返回指定元素在集合中的排名（下标）,集合中元素是按score从小到大排序的
zrevrank key member             #同上,但是集合中元素是按score从大到小排序
zrange key start end            #类似lrange操作从集合中去指定区间的元素。返回的是有序结果
zrevrange key start end         #同上，返回结果是按score逆序的
zrangebyscore key min max       #返回集合中score在给定区间的元素
zcount key min max              #返回集合中score在给定区间的数量
zcard key                       #返回集合中元素个数
zscore key element              #返回给定元素对应的score
zremrangebyrank key min max     #删除集合中排名在给定区间的元素
zremrangebyscore key min max    #删除集合中score在给定区间的元素
```



### Hash基本操作

```shell
hset key field value                                  #设置hash field为指定值，如果key不存在，则先创建
hget key field                                        #获取指定的hash field
hmget key filed1....fieldN                            #获取全部指定的hash filed
hmset key filed1 value1 ... filedN valueN             #同时设置hash的多个field
hincrby key field integer                             #将指定的hash filed 加上给定值
hexists key field                                     #测试指定field是否存在
hdel key field                                        #删除指定的hash field
hlen key                                              #返回指定hash的field数量
hkeys key                                             #返回hash的所有field
hvals key                                             #返回hash的所有value
hgetall                                               #返回hash的所有filed和value  
```





## Redis架构



### redis主从

提供服务端只有一台redis，主从两个库是全量数据，也可以充当消息队列,是一个单进程，多线程的服务

#### 原理

会在redis主库上启动一个线程，数据不停发送给从库，从库也会启动一个子线程，接受主库的数据，并放入内存中

#### 步骤

在另外一台机器上也安装redis

##### 1.安装、编译redis

```shell
#解压redis的tar包，然后进行编译
[root@node3 ~]# tar -zxvf redis-7.0.0\ \(1\).tar.gz 
[root@node3 ~]# cd redis-7.0.0/src/
[root@node3 src]# make PREFIX=/usr/bin/local/redis MALLOC=libc install 
```



##### 2.将redis配置到环境变量

```shell
[root@node3 redis]# cat /etc/profile.d/redis.sh  
export PATH=$PATH:/usr/bin/local/redis/bin 
[root@node3 redis]# . !$ 
[root@node3 redis]# redis-server  --version 
Redis server v=7.0.0 sha=00000000:0 malloc=libc bits=64 build=7aa698c81175c707
[root@node3 redis]# cd /usr/bin/local/redis 
```



##### 3.创建redis配置文件，更改为从库，并启动redis

```shell
[root@node3 redis]#mkdir etc data logs 
[root@node3 etc]# cat /usr/bin/local/redis/etc/redis.conf  
daemonize yes 
supervised systemd

#pid存放的位置
pidfile /var/run/redis.pid 
#监听的端口
port 6379 
#日志的存放位置
logfile "/usr/bin/local/redis/logs/redis.log" 
dbfilename dump.rdb
#持久化数据存放位置 
dir /usr/bin/local/redis/data/

#缓存持久化最大存储空间
maxmemory 1G 

#监听地址位置
bind 192.168.1.13 127.0.0.1 

#超时时间和日志级别
timeout 300 
loglevel notice 

#redis默认创建数据库数量
databases 16 

#存储持久化刷新时间
save 900 1 
save 300 10 
save 60 10000 

rdbcompression yes 

maxclients 10000 

#开启从库，并且从库只读 
slaveof <masterIP> 
slave-read-only yes  

#是否开启二进制日志，并设置二进制日志名称
appendonly yes 
appendfilename appendonly.aof 
appendfsync everysec 
[root@node3 etc]# redis-server  /usr/bin/local/redis/etc/redis.conf  
[root@node3 etc]# netstat  -ntpl 
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:3306            0.0.0.0:*               LISTEN      1246/mariadbd       
tcp        0      0 127.0.0.1:6379          0.0.0.0:*               LISTEN      4023/redis-server 1 
tcp        0      0 192.168.1.13:6379       0.0.0.0:*               LISTEN      4023/redis-server 1 
tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      733/rpcbind         
tcp        0      0 192.168.122.1:53        0.0.0.0:*               LISTEN      2137/dnsmasq        
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1118/sshd           
tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN      1120/cupsd          
tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      1415/master         
tcp        0      0 127.0.0.1:6010          0.0.0.0:*               LISTEN      1976/sshd: root@pts 
tcp6       0      0 :::3306                 :::*                    LISTEN      1246/mariadbd       
tcp6       0      0 :::111                  :::*                    LISTEN      733/rpcbind         
tcp6       0      0 :::22                   :::*                    LISTEN      1118/sshd           
tcp6       0      0 ::1:631                 :::*                    LISTEN      1120/cupsd          
tcp6       0      0 ::1:25                  :::*                    LISTEN      1415/master         
tcp6       0      0 ::1:6010                :::*                    LISTEN      1976/sshd: root@pts 
```



### redis-sentinel（redis哨兵）

#### 原理

当一个主库挂了的时候，哨兵会自动提升一个从库为主库，并且修改redis原本的VIP 将另外的一个从库绑定给新的主库，主库的死亡由两个从库进行判定，和mariadb的MHA原理类似

redis-sentinel是一个监视器，用来监视从库的状态，协调从库之间的同步



#### 配置

在安装redis的时候，redis-sentinel是一个默认被安装好的组件，只需要写配置文件就足够了



##### redis-sentinel配置项说明

```shell
# sentinel实例之间的通讯端口
port 26379

# sentinel需要监控的master信息：<mastername> <masterIP> <masterPort> <quorum>。
# <quorum>应该小于集群中slave的个数,只有当至少<quorum>个sentinel实例提交"master失效" 才会认为master为ODWON("客观"失效)。
sentinel monitor mymaster 192.168.0.1 6379 2

# 授权密码，在安全的环境中可以不设置
sentinel auth-pass mymaster xxxx

# master被当前sentinel实例认定为“失效”(SDOWN)的间隔时间
sentinel down-after-milliseconds mymaster 10000

# 当新master产生时，同时进行“slaveof”到新master并进行同步复制的slave个数。 
#在salve执行salveof与同步时，将会终止客户端请求。 此值较大，意味着“集群”终止客户端请求的时间总和和较大。 此值较小,意味着“集群”在故障转移期间，多个salve向客户端提供服务时仍然使用旧数据。 
sentinel parallel-syncs mymaster 1

# failover过期时间，当failover开始后，在此时间内仍然没有触发任何failover操作，当前sentinel将会认为此次failoer失败。
sentinel failover-timeout mymaster 10000

```



##### VIP配置VIP实现自动切换

如果需要实现VIP功能，需要借助一个脚本client-reconfig-script，接受7个参数

```shell
<master-name> <role> <state> <from-ip> <from-port> <to-ip> <to-port> 
```

to-ip这一项的IP地址，将会成为一个新的master，其他的则删除VIP，在failover的时候，只使用IP命令可能会引起arp问题，所以需要用arping命令来抛出GRAP，但是用这些命令需要使用root权限

###### 自动切换脚本：

```shell
#!/bin/sh
_DEBUG="on"
DEBUGFILE=/usr/local/redis/logs/sentinel_failover.log

VIP='192.168.147.100'
MASTERIP=${6}
MASK='24'
IFACE='ens33'
MYIP=$(ip -4 -o addr show dev ${IFACE}| grep -v secondary| awk '{split($4,a,"/");print a[1]}')


DEBUG () {
    if [ "$_DEBUG" = "on" ]; then
        $@
    fi
}


rm -rf ${DEBUGFILE}

set -e
DEBUG date >> ${DEBUGFILE}
DEBUG echo $@ >> ${DEBUGFILE}
DEBUG echo "Master: ${MASTERIP} My IP: ${MYIP}" >> ${DEBUGFILE}
if [ ${MASTERIP} == ${MYIP} ]; then
    if [ $(ip addr show ${IFACE} | grep ${VIP} | wc -l) -eq 0 ]; then
        ip addr add ${VIP}/${MASK} dev ${IFACE}
        DEBUG echo "ip addr add ${VIP}/${MASK} dev ${IFACE}" >> ${DEBUGFILE}
        arping -q -c 3 -A ${VIP} -I ${INTERFACE}
    fi
    exit 0
else
    if [ $(ip addr show ${IFACE} | grep ${VIP} | wc -l) -ne 0 ]; then
        ip addr del ${VIP}/${MASK} dev ${IFACE}
        DEBUG echo "ip addr del ${VIP}/${MASK} dev ${IFACE}" >> ${DEBUGFILE}
    fi
    exit 0
fi
exit 1
```



##### redis-sentinel配置文件

```shell
# /usr/local/redis/bin/sentinel.conf

port 26379

logfile /usr/local/redis/logs/redis-sentinel.log

daemonize yes

dir "/tmp"

sentinel monitor mymaster 192.168.0.1 6379 2

sentinel down-after-milliseconds mymaster 3000

sentinel parallel-syncs mymaster 1

sentinel failover-timeout mymaster 60000

sentinel client-reconfig-script mymaster /shell/redis_failover.sh
```





