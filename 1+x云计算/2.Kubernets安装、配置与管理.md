[toc]



# Kubernetes安装、配置与管理

| 节点                 | 主机名 | IP地址         |
| -------------------- | ------ | -------------- |
| Kubernets Master节点 | master | 192.168.100.10 |
| Kubernets Node节点   | node   | 192.168.100.20 |



# 一、Kubernetes安装



## 1、配置hosts文件（master和node节点均配置）

~~~powershell
[root@master ~]# vi /etc/hosts
//添加如下信息
192.168.100.10	master
192.168.100.20	node

[root@mastr ~]# scp /etc/hosts node:/etc/hosts
The authenticity of host 'node (192.168.100.20)' can't be established.
ECDSA key fingerprint is SHA256:G4McP9UHWCN8ERimLg4Jlw7fHdtmG2rU0XeS4XJqOFc.
ECDSA key fingerprint is MD5:64:ae:f8:6b:47:76:31:83:f6:e9:03:9b:dd:df:5a:4a.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'master,192.168.100.20' (ECDSA) to the list of known hosts.
root@node's password: 
hosts                                                                                                                                                   100%  200   152.5KB/s   00:00 
~~~



## 2、安装并启用时间同步服务

### 1）master节点

~~~powershell
[root@master ~]# yum install -y chrony

[root@master ~]# sed -i 's/^server/#&/' /etc/chrony.conf

[root@master ~]# cat >> /etc/chrony.conf << EOF
local stratum 10
server master iburst
allow all
EOF

[root@master ~]# systemctl enable chronyd
[root@master ~]# systemctl restart chronyd

[root@master ~]# timedatectl set-ntp true
~~~

### 2）node节点

~~~powershell
[root@node ~]# yum install -y chrony

[root@node ~]# sed -i 's/^server/#&/' /etc/chrony.conf

[root@node ~]# echo server 192.168.100.10 iburst >> /etc/chrony.conf

[root@node ~]# systemctl enable chronyd
[root@node ~]# systemctl restart chronyd

[root@node ~]# chronyc sources
MS Name/IP address         Stratum Poll Reach LastRx Last sample               
===============================================================================
^* master                       11   6     7     2    -13us[  -27ms] +/-   11ms		//此处由“^*”起始即为时间同步正常
~~~



## 3、Kubernetes安装

### 1）Master节点

~~~powershell
[root@master ~]# ./install.sh
请输入本节点IP:192.168.100.10

​~~~~~~~~~~~~~~~~~			//node节点加入kubernetes集群的命令
kubeadm join 192.168.100.10:6443 --token mds6pf.i7srthgga31079vn \
    --discovery-token-ca-cert-hash sha256:58938664b207a13f4202e331dd13f9079652e22ec384ddb904c900eea8371d83 
    
​~~~~~~~~~~~~~~~~~			//dashboard和kuboard登录所需要的令牌
token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC1hZG1pbi10b2tlbi16dmhtcyIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC1hZG1pbiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImM3MjRlZjlmLTNjOGUtMTFlYi1iMTgyLTAwMGMyOTQ0ZWNhNyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlcm5ldGVzLWRhc2hib2FyZC1hZG1pbiJ9.tYS9ZHPXNgaptqnDg-naF87vtlEk3o6xMk_hVFUKr8X7-eGxvBRKXBYkM-TvEr_23N1u_ORI13dOYM-wmaknCPCAXGAtx-U1342UcsvLH9e7dmsr-oniCzKyhU5uIHMD61IPhBXFjEWvi3xWAXmswwNuluzmWYmIwE3Lo0ON3DJoLtgkMt1eoKfjiPKJZedRx5gNNZbW0TiFwTDxbB6kZZxnJt8vaJjUVD6nWA53a_IogYXJwmT35dsY-CHiyJkyzHTZFb2Gd8MFi3b3xxPQuh0r7ZgzQgxy5M18Sfv2Zrg-q0tzAqvlZctaPFaLOx87Nxb5lkzG4lq5Q_lRZKnjYQ


~~~

### 2）Node节点

~~~powershell
[root@node ~]# yum install -y kubelet-1.14.1 kubeadm-1.14.1 kubectl-1.14.1

[root@node ~]# ./kubernetes_base.sh 

[root@node ~]# kubeadm join 192.168.100.10:6443 --token mds6pf.i7srthgga31079vn --discovery-token-ca-cert-hash sha256:58938664b207a13f4202e331dd13f9079652e22ec384ddb904c900eea8371d83 
~~~

Node节点加入成功之后，可以返回Master节点，进行检查。

~~~powershell
[root@master ~]# kubectl get nodes
NAME     STATUS   ROLES    AGE     VERSION
master   Ready    master   5m26s   v1.14.1
node     Ready    <none>   16s     v1.14.1
~~~

使用Firefox输入https://192.168.100.10:30000，可以浏览Kubernetes Dashboard。

### 3）配置Kuoard

~~~powershell
[root@master ~]# kubectl create -f yaml/kuboard.yaml 
deployment.apps/kuboard created
service/kuboard created
serviceaccount/kuboard-user created
clusterrolebinding.rbac.authorization.k8s.io/kuboard-user created
serviceaccount/kuboard-viewer created
clusterrolebinding.rbac.authorization.k8s.io/kuboard-viewer created
clusterrolebinding.rbac.authorization.k8s.io/kuboard-viewer-node created
clusterrolebinding.rbac.authorization.k8s.io/kuboard-viewer-pvp created
ingress.extensions/kuboard created
~~~

使用http://192.168.100.10:31000，可以浏览Kuboard。



# 二、Kubectl命令使用



## 1、查看nodes、cs、pods的状态

~~~powershell
[root@master ~]# kubectl get node -n kube-system
NAME     STATUS   ROLES    AGE   VERSION
master   Ready    master   98m   v1.14.1
node     Ready    <none>   93m   v1.14.1

[root@master ~]# kubectl get cs -n kube-system
NAME                 STATUS    MESSAGE             ERROR
controller-manager   Healthy   ok                  
scheduler            Healthy   ok                  
etcd-0               Healthy   {"health":"true"}   

[root@master ~]# kubectl get pods -n kube-system
NAME                                    READY   STATUS    RESTARTS   AGE
coredns-8686dcc4fd-bpvn2                1/1     Running   0          98m
coredns-8686dcc4fd-bsr5v                1/1     Running   0          98m
etcd-master                             1/1     Running   0          97m
kube-apiserver-master                   1/1     Running   0          97m
kube-controller-manager-master          1/1     Running   0          97m
kube-flannel-ds-amd64-8tllz             1/1     Running   0          98m
kube-flannel-ds-amd64-tbvr6             1/1     Running   0          93m
kube-proxy-c8zqh                        1/1     Running   0          61m
kube-proxy-sh849                        1/1     Running   0          61m
kube-scheduler-master                   1/1     Running   0          97m
kubernetes-dashboard-5f7b999d65-jh24s   1/1     Running   0          97m
kuboard-84979d978d-69d7g                1/1     Running   0          73m
~~~



## 2、kubectl常用命令整理

### 1）namespace 名称空间

使用kubectl进行查询、创建或者删除等操作，如果不标识namespace，则默认对default这个namespace中的对象进行操作。若需要操作其他namespace的对象操作，都需要标识namespace。

~~~powershell
[root@master ~]# kubectl get namespace
NAME              STATUS   AGE
default           Active   105m
kube-node-lease   Active   105m
kube-public       Active   105m
kube-system       Active   105m

[root@master ~]# kubectl create namespace blog
namespace/blog created
~~~

### 2）kubectl create			创建资源对象

~~~powershell
[root@master ~]# kubectl create -f yaml/wordpress-db.yaml  -n blog
deployment.apps/mysql-deploy created
service/mysql created

[root@master ~]# kubectl create deployment nginx --image nginx:latest
deployment.apps/nginx created
~~~

### 3）kubectl run					创建容器

~~~powershell
[root@master ~]# kubectl run nginx2 --image=nginx:latest
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
deployment.apps/nginx2 created

[root@master ~]# kubectl run nginx3 --image=nginx:latest --image-pull-policy=Never --replicas=4
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
deployment.apps/nginx3 created
~~~

### 4）kubectl get					查看资源对象列表

~~~powershell
[root@master ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
nginx-7bf7cc574b-qgxbw   1/1     Running   0          18m
nginx-7bf7cc574b-xw4j2   1/1     Running   0          19m

[root@master ~]# kubectl get pods -n kube-system
NAME                                    READY   STATUS    RESTARTS   AGE
coredns-8686dcc4fd-bpvn2                1/1     Running   0          97m
coredns-8686dcc4fd-bsr5v                1/1     Running   0          97m
etcd-master                             1/1     Running   0          96m
kube-apiserver-master                   1/1     Running   0          96m
kube-controller-manager-master          1/1     Running   0          96m
kube-flannel-ds-amd64-8tllz             1/1     Running   0          97m
kube-flannel-ds-amd64-sh849             1/1     Running   0          29m
kube-flannel-ds-amd64-tbvr6             1/1     Running   0          92m
kube-proxy-9h6s8                        1/1     Running   0          92m
kube-proxy-jzwvf                        1/1     Running   0          97m
kube-proxy-vg86l                        1/1     Running   0          29m
kube-scheduler-master                   1/1     Running   0          96m
kubernetes-dashboard-5f7b999d65-jh24s   1/1     Running   0          97m
kuboard-84979d978d-69d7g                1/1     Running   0          72m

[root@master ~]# kubectl get svc -n kube-system
NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE
kube-dns               ClusterIP   10.96.0.10      <none>        53/UDP,53/TCP,9153/TCP   98m
kubernetes-dashboard   NodePort    10.110.97.253   <none>        443:30000/TCP            97m
kuboard                NodePort    10.101.232.31   <none>        80:31000/TCP             72m
~~~

常用的资源对象类型

| 资源对象类型 | 说明        |
| ------------ | ----------- |
| pod          | 容器        |
| node         | 节点        |
| namespace    | 名称空间    |
| service      | 服务（svc） |
| deployment   | 发布        |

### 5）kubectl describe			显示资源对象的详细信息

~~~powershell
[root@master ~]# kubectl describe node master
Name:               master
Roles:              master
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=master
                    kubernetes.io/os=linux
                    node-role.kubernetes.io/master=
Annotations:        flannel.alpha.coreos.com/backend-data: {"VtepMAC":"96:f1:d2:58:e4:1a"}
                    flannel.alpha.coreos.com/backend-type: vxlan
                    flannel.alpha.coreos.com/kube-subnet-manager: true
                    flannel.alpha.coreos.com/public-ip: 192.168.100.10
                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Sat, 12 Dec 2020 10:28:32 -0500
Taints:             <none>
Unschedulable:      false
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Sat, 12 Dec 2020 12:02:18 -0500   Sat, 12 Dec 2020 10:28:27 -0500   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Sat, 12 Dec 2020 12:02:18 -0500   Sat, 12 Dec 2020 10:28:27 -0500   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Sat, 12 Dec 2020 12:02:18 -0500   Sat, 12 Dec 2020 10:28:27 -0500   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Sat, 12 Dec 2020 12:02:18 -0500   Sat, 12 Dec 2020 10:29:13 -0500   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.100.10
  Hostname:    master
Capacity:
 cpu:                2
 ephemeral-storage:  47781076Ki
 hugepages-1Gi:      0
 hugepages-2Mi:      0
 memory:             7990116Ki
 pods:               110
Allocatable:
 cpu:                2
 ephemeral-storage:  44035039569
 hugepages-1Gi:      0
 hugepages-2Mi:      0
 memory:             7887716Ki
 pods:               110
System Info:
 Machine ID:                 16fb2b1c86e7457baf1f9ca3d24985eb
 System UUID:                A97E4D56-39CE-2580-57D8-5EAC3F44ECA7
 Boot ID:                    f467df27-8f2d-4d77-a1b6-094c9b67ebc3
 Kernel Version:             3.10.0-1062.7.1.el7.x86_64
 OS Image:                   CentOS Linux 7 (Core)
 Operating System:           linux
 Architecture:               amd64
 Container Runtime Version:  docker://18.9.6
 Kubelet Version:            v1.14.1
 Kube-Proxy Version:         v1.14.1
PodCIDR:                     10.16.0.0/24
Non-terminated Pods:         (9 in total)
  Namespace                  Name                                     CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE
  ---------                  ----                                     ------------  ----------  ---------------  -------------  ---
  kube-system                coredns-8686dcc4fd-bpvn2                 100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     94m
  kube-system                coredns-8686dcc4fd-bsr5v                 100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     94m
  kube-system                etcd-master                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         92m
  kube-system                kube-apiserver-master                    250m (12%)    0 (0%)      0 (0%)           0 (0%)         92m
  kube-system                kube-controller-manager-master           200m (10%)    0 (0%)      0 (0%)           0 (0%)         93m
  kube-system                kube-flannel-ds-amd64-8tllz              100m (5%)     100m (5%)   50Mi (0%)        50Mi (0%)      93m
  kube-system                kube-proxy-jzwvf                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         94m
  kube-system                kube-scheduler-master                    100m (5%)     0 (0%)      0 (0%)           0 (0%)         93m
  kube-system                kubernetes-dashboard-5f7b999d65-jh24s    0 (0%)        0 (0%)      0 (0%)           0 (0%)         93m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (42%)  100m (5%)
  memory             190Mi (2%)  390Mi (5%)
  ephemeral-storage  0 (0%)      0 (0%)
Events:              <none>

[root@master ~]# kubectl describe pod nginx-7bf7cc574b-qgxbw
Name:               nginx-7bf7cc574b-qgxbw
Namespace:          default
Priority:           0
PriorityClassName:  <none>
Node:               node2/192.168.100.30
Start Time:         Sat, 12 Dec 2020 11:47:39 -0500
Labels:             pod-template-hash=7bf7cc574b
                    run=nginx
Annotations:        <none>
Status:             Running
IP:                 10.16.2.4
Controlled By:      ReplicaSet/nginx-7bf7cc574b
Containers:
  nginx:
    Container ID:   docker://dc620b1436c9397850d754ffb27e4faca3f409df59d17a95ba95948b81fc86e1
    Image:          nginx:latest
    Image ID:       docker://sha256:540a289bab6cb1bf880086a9b803cf0c4cefe38cbb5cdefa199b69614525199f
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Sat, 12 Dec 2020 11:47:42 -0500
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4gkqt (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-4gkqt:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-4gkqt
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  14m   default-scheduler  Successfully assigned default/nginx-7bf7cc574b-qgxbw to node2
  Normal  Pulled     14m   kubelet, node2     Container image "nginx:latest" already present on machine
  Normal  Created    14m   kubelet, node2     Created container nginx
  Normal  Started    14m   kubelet, node2     Started container nginx
  
[root@master ~]# kubectl describe svc kuboard -n kube-system
Name:                     kuboard
Namespace:                kube-system
Labels:                   <none>
Annotations:              <none>
Selector:                 k8s.eip.work/layer=monitor,k8s.eip.work/name=kuboard
Type:                     NodePort
IP:                       10.101.232.31
Port:                     http  80/TCP
TargetPort:               80/TCP
NodePort:                 http  31000/TCP
Endpoints:                10.16.1.2:80
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   <none>
~~~

### 6）kubectl delete				删除资源对象

~~~powershell
[root@master ~]# kubectl delete pod nginx-7bf7cc574b-46srg
pod "nginx-7bf7cc574b-46srg" deleted

[root@master ~]# kubectl delete deployment nginx
deployment.extensions "nginx" deleted
~~~

### 7）kubectl exec					容器操作

~~~powershell
[root@master images]# kubectl exec --stdin --tty nginx-7bf7cc574b-6fj24 -- /bin/bash

root@nginx-7bf7cc574b-6fj24:/# ls /
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
~~~

### 8）kubectl expose				开放容器端口

~~~powershell
[root@master ~]# kubectl expose deploy/nginx --port 80
service/nginx exposed

[root@master ~]# kubectl get svc
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP   45m
nginx        ClusterIP   10.107.160.170   <none>        80/TCP    9s
~~~



# 三、Kubernetes的测试与使用



## 1、开启IPVS

修改kube-proxy的配置文件之后，重启kube-proxy服务

~~~powershell
[root@master ~]# kubectl edit cm kube-proxy -n kube-system
..................
    mode: "ipvs"
..................

[root@master ~]# kubectl get pod -n kube-system | grep kube-proxy| awk '{system("kubectl delete pod "$1" -n kube-system")}'
pod "kube-proxy-9h6s8" deleted
pod "kube-proxy-jzwvf" deleted

[root@master ~]# kubectl logs kube-proxy-c8zqh -n kube-system
I1212 16:03:12.493995       1 server_others.go:177] Using ipvs Proxier.		//此处说明ipvs已经启用
W1212 16:03:12.494523       1 proxier.go:381] IPVS scheduler not specified, use rr by default
I1212 16:03:12.495902       1 server.go:555] Version: v1.14.1
I1212 16:03:12.506291       1 conntrack.go:52] Setting nf_conntrack_max to 131072
I1212 16:03:12.506704       1 config.go:202] Starting service config controller
I1212 16:03:12.506780       1 controller_utils.go:1027] Waiting for caches to sync for service config controller
I1212 16:03:12.506864       1 config.go:102] Starting endpoints config controller
I1212 16:03:12.506878       1 controller_utils.go:1027] Waiting for caches to sync for endpoints config controller
I1212 16:03:12.607373       1 controller_utils.go:1034] Caches are synced for service config controller
I1212 16:03:12.607461       1 controller_utils.go:1034] Caches are synced for endpoints config controller

[root@master ~]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  172.17.0.1:31000 rr
  -> 10.16.1.2:80                 Masq    1      0          0         
TCP  192.168.100.10:31000 rr
  -> 10.16.1.2:80                 Masq    1      0          0         
TCP  10.16.0.0:30000 rr
  -> 10.16.0.4:8443               Masq    1      0          0         
TCP  10.16.0.0:31000 rr
  -> 10.16.1.2:80                 Masq    1      0          0         
TCP  10.16.0.1:31000 rr
  -> 10.16.1.2:80                 Masq    1      0          0         
TCP  10.96.0.1:443 rr
  -> 192.168.100.10:6443          Masq    1      0          0         
TCP  10.96.0.10:53 rr
  -> 10.16.0.2:53                 Masq    1      0          0         
  -> 10.16.0.3:53                 Masq    1      0          0         
TCP  10.96.0.10:9153 rr
  -> 10.16.0.2:9153               Masq    1      0          0         
  -> 10.16.0.3:9153               Masq    1      0          0         
TCP  10.101.232.31:80 rr
  -> 10.16.1.2:80                 Masq    1      0          0         
TCP  10.110.97.253:443 rr
  -> 10.16.0.4:8443               Masq    1      0          0         
TCP  127.0.0.1:30000 rr
  -> 10.16.0.4:8443               Masq    1      0          0         
TCP  127.0.0.1:31000 rr
  -> 10.16.1.2:80                 Masq    1      0          0         
TCP  172.17.0.1:30000 rr
  -> 10.16.0.4:8443               Masq    1      0          0         
TCP  192.168.100.10:30000 rr
  -> 10.16.0.4:8443               Masq    1      0          0         
TCP  10.16.0.1:30000 rr
  -> 10.16.0.4:8443               Masq    1      0          0         
UDP  10.96.0.10:53 rr
  -> 10.16.0.2:53                 Masq    1      0          0         
  -> 10.16.0.3:53                 Masq    1      0          0         
~~~



## 2、调度master节点

出于安全考虑，默认配置下Kubernetes不会将Pod调度到Master节点。查看Master节点Taints字段默认配置：

~~~powershell
[root@master ~]# kubectl describe node master
……
CreationTimestamp: Fri, 04 Oct 2019 06:16:45 +0000
Taints: node-role.kubernetes.io/master:NoSchedule		//状态为NoSchedule
Unschedulable: false

[root@master ~]# kubectl taint node master node-role.kubernetes.io/master-
master untainted

[root@master ~]# kubectl describe node master
……
CreationTimestamp: Fri, 04 Oct 2019 06:16:45 +0000
Taints: <none>		//状态已经改变
Unschedulable: false
~~~



## 3、运行容器

~~~powershell
[root@master ~]# kubectl run nginx --image=nginx:latest --image-pull-policy=Never --replicas=4
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
deployment.apps/nginx created

[root@master ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
nginx-7bf7cc574b-6492z   1/1     Running   0          35s
nginx-7bf7cc574b-fv7lm   1/1     Running   0          35s
nginx-7bf7cc574b-vg86l   1/1     Running   0          35s
nginx-7bf7cc574b-xw4j2   1/1     Running   0          35s

[root@master ~]# kubectl expose deploy/nginx --port 80
service/nginx exposed

[root@master ~]# kubectl get svc
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP   45m
nginx        ClusterIP   10.107.160.170   <none>        80/TCP    9s

[root@master ~]# curl 10.107.160.170:80
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
~~~



# 四、Kubernetes部署Wordpress



## 1、新建namespace

~~~powershell
[root@master ~]# kubectl create namespace blog
namespace/blog created
~~~



## 2、部署应用

~~~powershell
[root@master ~]# kubectl create -f yaml/wordpress-db.yaml  -n blog
deployment.apps/mysql-deploy created
service/mysql created

[root@master ~]# kubectl get svc -n blog
NAME    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
mysql   ClusterIP   10.105.40.183   <none>        3306/TCP   36s	//记录此处mysql svc的CLUSTER-IP

[root@master ~]# vi yaml/wordpress.yaml 
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: wordpress-deploy
  namespace: blog
  labels:
    app: wordpress
.........................
        env:
        - name: WORDPRESS_DB_HOST
          value: 10.105.40.183:3306				//此处的IP，是mysql svc的clusterIP
        - name: WORDPRESS_DB_USER
          value: wordpress
        - name: WORDPRESS_DB_PASSWORD
          value: wordpress
..........................

[root@master ~]# kubectl create -f yaml/wordpress.yaml  -n blog
deployment.apps/wordpress-deploy created
service/wordpress created

[root@master ~]# kubectl create -f yaml/wordpress-pod.yaml  -n blog
pod/wordpress created

[root@master ~]# kubectl get svc -n blog
NAME        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
mysql       ClusterIP   10.105.40.183   <none>        3306/TCP       111s
wordpress   NodePort    10.97.59.125    <none>        80:30691/TCP   39s		//wordpress的端口为30691，端口是随机生成

[root@master ~]# kubectl get pods -n blog
NAME                               READY   STATUS    RESTARTS   AGE
mysql-deploy-78cd6964bd-6pcxh      1/1     Running   0          3m12s
wordpress                          2/2     Running   0          93s
wordpress-deploy-969974bf4-lxtzd   1/1     Running   0          2m
~~~



# 五、Kubernetes运维

| 节点                 | 主机名 | IP地址         |
| -------------------- | ------ | -------------- |
| Kubernets Master节点 | master | 192.168.100.10 |
| Kubernets Node节点   | node   | 192.168.100.20 |
| Kubernets Node节点   | node2  | 192.168.100.30 |



## 1、Node扩容

### 1）Master重新生成Token以及获取CA证书的SHA校验值

Kubernetes默认的Token有效期为24小时，当过期之后，该Token就不可用了。登录master节点，生成一条永久有效的Token。并获取CA证书sha256编码hash值。

~~~powershell
[root@master ~]# kubeadm token create --ttl 0
29ikut.hbjruxqy6dgvgwgd

[root@master ~]# openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'
58938664b207a13f4202e331dd13f9079652e22ec384ddb904c900eea8371d83
~~~

### 2）Node2安装准备

#### a、hosts文件准备

~~~powershell
[root@node2 ~]# vi /etc/hosts
..........
192.168.100.10  master
192.168.100.20  node
192.168.100.30  node2

[root@node2 ~]# scp /etc/hosts 192.168.100.10:/etc/hosts

[root@node2 ~]# scp /etc/hosts 192.168.100.20:/etc/hosts

~~~

#### b、安装并配置时间同步服务

~~~powershell
[root@node2 ~]# yum install -y chrony

[root@node2 ~]# sed -i 's/^server/#&/' /etc/chrony.conf

[root@node2 ~]# echo server 192.168.100.10 iburst >> /etc/chrony.conf

[root@node2 ~]# systemctl enable chronyd
[root@node2 ~]# systemctl restart chronyd

[root@node2 ~]# chronyc sources
MS Name/IP address         Stratum Poll Reach LastRx Last sample               
===============================================================================
^* master                       11   6     7     2    -13us[  -27ms] +/-   11ms		//此处由“^*”起始即为时间同步正常
~~~

#### c、安装Kubernetes

~~~powershell
[root@node2 ~]# yum install -y kubelet-1.14.1 kubeadm-1.14.1 kubectl-1.14.1

[root@node2 ~]# systemctl enable kubelet && systemctl start kubelet
~~~

#### d、Node2加入Kubernetes集群

~~~powershell
[root@node2 ~]# kubeadm join 192.168.100.10:6443 --token 29ikut.hbjruxqy6dgvgwgd --discovery-token-ca-cert-hash sha256:58938664b207a13f4202e331dd13f9079652e22ec384ddb904c900eea8371d83
[preflight] Running pre-flight checks
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'
[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.14" ConfigMap in the kube-system namespace
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Activating the kubelet service
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
~~~

成功之后，可以返回Master节点，查看节点信息。

~~~powershell
[root@master ~]# kubectl get nodes
NAME     STATUS   ROLES    AGE   VERSION
master   Ready    master   68m   v1.14.1
node     Ready    <none>   63m   v1.14.1
node2    Ready    <none>   11s   v1.14.1
~~~



## 2、Node的隔离与恢复

### 1）隔离Node

在硬件升级、硬件维护等情况下，需要将某些Node隔离。使用kubectl cordon <node_name>命令可禁止Pod调度到该节点上，在其上运行的Pod并不会自动停止，管理员需要手动停止在该Node上运行的Pod。对于后续创建的Pod，系统将不会再向该Node进行调度。

~~~powershell
[root@master ~]# kubectl cordon node
node/node cordoned

[root@master ~]# kubectl get nodes
NAME     STATUS                     ROLES    AGE     VERSION
master   Ready                      master   70m     v1.14.1
node     Ready,SchedulingDisabled   <none>   65m     v1.14.1
node2    Ready                      <none>   2m21s   v1.14.1
~~~

### 2）恢复Node

~~~powershell
[root@master ~]# kubectl uncordon node
node/node uncordoned
~~~

### 3）驱逐Node

通过kubectl drain <node>命令可实现对node节点的驱逐，该命令会删除该节点上的所有Pod（DaemonSet除外），在其他Node上重新启动它们。

~~~powershell
[root@master ~]# kubectl drain node
~~~



## 3、Pod动态扩容和缩放

### 1）运行Deployment

~~~powershell
[root@master ~]# kubectl run nginx --image-pull-policy=Never --image=nginx:latest
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
deployment.apps/nginx created

[root@master ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
nginx-7bf7cc574b-xw4j2   1/1     Running   0          2s
~~~

### 2）Pod扩容

~~~powershell
[root@master ~]# kubectl scale deployment nginx --replicas=5
deployment.extensions/nginx scaled

[root@master ~]# kubectl get pods
NAME                     READY   STATUS              RESTARTS   AGE
nginx-7bf7cc574b-6pcxh   0/1     ContainerCreating   0          3s
nginx-7bf7cc574b-gbwfl   0/1     ContainerCreating   0          3s
nginx-7bf7cc574b-lxtzd   0/1     ContainerCreating   0          3s
nginx-7bf7cc574b-qgxbw   0/1     ContainerCreating   0          3s
nginx-7bf7cc574b-xw4j2   1/1     Running             0          42s

[root@master ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
nginx-7bf7cc574b-6pcxh   1/1     Running   0          8s
nginx-7bf7cc574b-gbwfl   1/1     Running   0          8s
nginx-7bf7cc574b-lxtzd   1/1     Running   0          8s
nginx-7bf7cc574b-qgxbw   1/1     Running   0          8s
nginx-7bf7cc574b-xw4j2   1/1     Running   0          47s
~~~

### 3）Pod缩容

将--replicas设置为比当前Pod副本数量更小的数字，系统将会“杀掉”一些运行中的Pod，即可实现应用集群缩容。

~~~powershell
[root@master ~]# kubectl scale deployment nginx --replicas=2
deployment.extensions/nginx scaled

[root@master ~]# kubectl get pods
NAME                     READY   STATUS        RESTARTS   AGE
nginx-7bf7cc574b-6pcxh   0/1     Terminating   0          71s
nginx-7bf7cc574b-gbwfl   0/1     Terminating   0          71s
nginx-7bf7cc574b-lxtzd   0/1     Terminating   0          71s
nginx-7bf7cc574b-qgxbw   1/1     Running       0          71s
nginx-7bf7cc574b-xw4j2   1/1     Running       0          110s

[root@master ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
nginx-7bf7cc574b-qgxbw   1/1     Running   0          92s
nginx-7bf7cc574b-xw4j2   1/1     Running   0          2m11s
~~~

