## 案例二：OpenStack平台调度策略优化[Openstack平台调度策略优化.mp4](https://fdfs.douxuedu.com/group1/M00/00/4A/wKggBmIq4j6ESLOHAAAAAAMjyTU068.mp4)

### 案例准备

#### 1. 规划节点

根据云平台分配的主机。节点规划见表1。

表1 节点规划

| **IP**         | **主机名** | **节点** |
| :------------- | :--------- | :------- |
| 192.168.200.11 | controller | 控制节点 |

#### 2. 基础准备

根据云平台分配的第二台主机All in one作为实验节点，该案例只研究云平台在大规模创建云主机遇到特定报错时的解决方法。

### 案例实施

#### 1. OpenStack平台报错分析

在OpenStack平台经历大并发的时候，比如同一个平台，大量的用户同时创建云主机（单个用户创建大量云主机不会触发此种现象），会达到云平台的性能瓶颈，导致创建云主机报错。

大量用户同时创建云主机，会对云平台的两个服务造成性能瓶颈，一个是RabbitMQ，当RabbitMQ达到瓶颈时，会报如下错误：

```shell
ERROR oslo.messaging._drivers.impl_rabbit [req-eb79ea09-247e-49e0-960b-0896ef978661 - - - - -] [303415c0-e494-4ea2-8158-d66d4165600d] AMQP server on controller:5672 is unreachable: timed out. Trying again in 10 seconds.: timeout: timed out
```

另一个就是DHCP。本案例重点讨论DHCP报错的情况，不考虑RabbitMQ的性能瓶颈。DHCP报错信息如下：

```shell
WARNING nova.compute.manager [req-8d9240cd-6a47-4979-a289-bdd58d399f0a 891c061e4aea4af8909a4affe0c24f92 c509a52800de4902845460fcc5318f3f - 8d899afee33641e0a094f85fbeb9b2c6 8d899afee33641e0a094f85fbeb9b2c6] [instance: 374aa944-6cd7-4dbf-a741-5bd44623919d] Received unexpected event network-vif-plugged-b803941a-c3ae-45d7-b962-13ba1ff00a31 for instance with vm_state active and task_state None.
```

在这种情况下，因为大量的创建云主机，导致获取IP地址超时，然后就发生了如上的报错。

**注意：这个报错还和计算节点的性能有关，大量创建云主机的时候，计算节点如果没有创建过该镜像的云主机，会先从控制节点复制镜像到计算节点，这也会导致速度变慢。而且在创建大量云主机的时候，对计算节点的硬盘也是一个考验，如果硬盘性能差的话，也会导致创建速度慢，大量排队，超时等现象。**

#### 2. 解决策略

在解决问题之前，首先了解创建云主机的过程，在创建虚机过程中，Nova-compute会调用wait_for_instance_event函数（nova/compute/manage.py）进行network-vif-plugged的事件等待。

在Nova-compute配置文件中有两个与该事件相关的参数- vif_plugging_timeout、vif_plugging_if_fatal，前者是等待事件的最大时间，后者是处理超时异常的方式。若在规定时间内，Nova-compute接受到了事件响应，那么虚机可正常创建，那么当超时现象发生时，Nova-compute会根据vif_plugging_is_fatal的配置采取两种处理方式。

若超时发生，并且配置文件中vif_plugging_is_fatal为True，Nova首先执行guest.poweroff，停止Qemu进程；然后执行cleanup函数，先清除网络资源，使用函数_unplug_vifs，删除plug_vifs函数创建的ovs port，ovs agent检测到了删除端口的事件然后通知Neutron-server删除neutron db中的port信息，最后抛VirtualInterfaceCreateException。

如果vif_plugging_is_fatal为False，即便发生eventlet.timeout.Timeout异常，创建过程也会继续。然后等虚拟机创建成功后，依然可以拿到IP地址。

通过上述虚拟机创建的过程，对于上述云平台发生的错误，就有了解决的思路，通过修改/etc/nova/nova.conf配置文件，将vif_plugging_is_fatal参数由true改为false，命令如下：

切换至云平台第二个节点主机，修改/etc/nova/nova.conf配置文件：

```shell
[root@controller ~]# vi /etc/nova/nova.conf
```

找到如下这行：

```shell
#vif_plugging_is_fatal=true
```

将该行的注释去掉，并将true改为false，修改完之后如下：

```shell
vif_plugging_is_fatal=false
```

保存退出nova.conf，最后重启Nova服务，也可以重启所有服务，命令如下：

```shell
[root@controller ~]# openstack-service restart
```

等待重启完毕即可。通过该参数的修改，可解决在大并发量创建虚拟机时，因排队超时导致虚拟机获取不到IP地址的报错。

