## 案例二：RabbitMQ服务优化[RabbitMQ服务优化.mp4](https://fdfs.douxuedu.com/group1/M00/00/4A/wKggBmIqwaaEB3FuAAAAAFylgPg056.mp4)

### 案例准备

#### 1. 规划节点

节点规划见表1。

表1 节点规划

| **IP**        | **主机名** | **节点**                 |
| :------------ | :--------- | :----------------------- |
| 10.24.200.130 | controller | OpenStack Controller节点 |

#### 2. 基础准备

使用云主机搭建的OpenStack平台作为实验节点。10.24.200.130是OpenStack平台的Controller节点。OpenStack各个组件内部的各个服务进程之间则是通过基于AMPQ的RPC方式进行通信，实现RPC通信需借助RabbitMQ消息队列，在大访问量的情况下，对RabbitMQ服务有一定的压力。

### 案例实施

#### RabbitMQ的优化

RabbitMQ的连接数是压垮消息队列的一个重要的指标。所以在平时使用OpenStack平台的过程中，如果大量的用户同时创建虚拟机，会导致云平台创建报错，其实就是消息队列服务的崩溃。

在优化方面，我们首先想到，是将RabbitMQ服务默认的连接数量改大，修改方法如下：

（1）系统级别修改

使用CRT等远程工具连接到Controller节点，然后修改配置文件。

编辑/etc/sysctl.conf配置文件：

```
[root@controller ~]# vi /etc/sysctl.conf
fs.file-max=10240
#在sysctl.conf文件的最下方添加一行fs.file-max=10240
```

修改完毕后保存退出并生效配置，命令如下：

```
[root@controller ~]# sysctl -p
fs.file-max = 10240
```

（2）用户级别修改

用户级别修改，编辑/etc/security/limits.conf配置文件，具体命令如下：

```
[root@controller ~]# vi /etc/security/limits.conf
openstack  soft     nofile  10240
openstack  hard     nofile  10240
#在配置文件的最后添加两行内容如上
```

修改完之后，保存退出。

（3）修改RabbitMQ配置

修改RabbitMQ服务的Service配置文件rabbitmq-server.service，具体命令如下：

```
[root@controller ~]# vi /usr/lib/systemd/system/rabbitmq-server.service
```

在[Service]下添加一行参数如下：

```
LimitNOFILE=10240
```

编辑完之后保存退出，重启RabbitMQ服务，命令如下：

```
[root@controller ~]# systemctl daemon-reload
[root@controller ~]# systemctl restart rabbitmq-server
```

重启完毕后，查看RabbitMQ的最大连接数，命令如下：

```
[root@controller ~]# rabbitmqctl status
Status of node rabbit@openstack
...忽略输出...
 {file_descriptors,
     [{total_limit,10140},
      {total_used,53},
      {sockets_limit,9124},
      {sockets_used,51}]},
```

可以看到当前的RabbitMQ已被修改。